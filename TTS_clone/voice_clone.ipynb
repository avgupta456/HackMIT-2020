{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesizer.inference import Synthesizer\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "import sounddevice as sd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import wave\n",
    "import librosa\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
      "Found synthesizer \"pretrained\" trained to step 278000\n",
      "Building Wave-RNN\n",
      "Trainable Parameters: 4.481M\n",
      "Loading model weights at vocoder/saved_models/pretrained/pretrained.pt\n",
      "Total time: 0.09991312026977539\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "encoder.load_model(Path(\"encoder/saved_models/pretrained.pt\"))\n",
    "synthesizer = Synthesizer(Path(\"synthesizer/saved_models/logs-pretrained/taco_pretrained\"))\n",
    "vocoder.load_model(Path(\"vocoder/saved_models/pretrained/pretrained.pt\"))\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Total time: {stop - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from the documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"samples/elon_voice.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_wav, sampling_rate = librosa.load(str(audio_file_path))\n",
    "preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = encoder.embed_utterance(preprocessed_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get text\n",
    "text = \"When something is important enough, you do it even if the odds are not in your favor.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text]\n",
    "embeds = [embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mel spectogram\n",
    "specs = synthesizer.synthesize_spectrograms(texts, embeds)\n",
    "spec = specs[0]\n",
    "print(\"Created the mel spectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating the waveform\n",
    "print(\"Synthesizing the waveform:\")\n",
    "# Synthesizing the waveform is fairly straightforward. Remember that the longer the\n",
    "# spectrogram, the more time-efficient the vocoder.\n",
    "start = time.time()\n",
    "generated_wav = vocoder.infer_waveform(spec)\n",
    "stop = time.time()\n",
    "print(f\"\\nTotal time: {stop - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad it to prevent from cutting audio\n",
    "generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim excess silences to compensate for gaps in spectrograms (issue #53)\n",
    "generated_wav = encoder.preprocess_wav(generated_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_wav = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_audio(text, audio_path):\n",
    "    \"\"\"\n",
    "    Convert individual sentence to cloned audio.\n",
    "    @Param:\n",
    "    1. text - sentence. (string)\n",
    "    2. audio_path - relative path for original .wav file. (must be .wav)\n",
    "    \"\"\"\n",
    "    audio_file_path = audio_path\n",
    "    original_wav, sampling_rate = librosa.load(str(audio_file_path))\n",
    "    preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
    "    embed = encoder.embed_utterance(preprocessed_wav)\n",
    "    texts = [text]\n",
    "    embeds = [embed]\n",
    "    #create mel spectogram\n",
    "    specs = synthesizer.synthesize_spectrograms(texts, embeds)\n",
    "    spec = specs[0]\n",
    "    print(\"Created the mel spectrogram\")\n",
    "    ## Generating the waveform\n",
    "    print(\"Synthesizing the waveform:\")\n",
    "    # Synthesizing the waveform is fairly straightforward. Remember that the longer the\n",
    "    # spectrogram, the more time-efficient the vocoder.\n",
    "    start = time.time()\n",
    "    generated_wav = vocoder.infer_waveform(spec)\n",
    "    stop = time.time()\n",
    "    print(f\"\\nTotal time: {stop - start}\")\n",
    "    #pad it to prevent from cutting audio\n",
    "    generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
    "    # Trim excess silences to compensate for gaps in spectrograms (issue #53)\n",
    "    generated_wav = encoder.preprocess_wav(generated_wav)\n",
    "    global_wav.append(generated_wav)\n",
    "    return generated_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated_wav = text_to_audio(text, audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio (non-blocking)\n",
    "try:\n",
    "    sd.stop()\n",
    "    sd.play(generated_wav, synthesizer.sample_rate)\n",
    "except sd.PortAudioError as e:\n",
    "    print(\"\\nCaught exception: %s\" % repr(e))\n",
    "    print(\"Continuing without audio playback. Suppress this message with the \\\"--no_sound\\\" flag.\\n\")\n",
    "except:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implement using multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"samples/elon_voice.wav\"\n",
    "#get text\n",
    "text0 = \"When something is important enough, you do it even if the odds are not in your favor.\"\n",
    "text1 = \"Multiprocessing refers to the ability of a system to support more than one processor at the same time.\"\n",
    "text = [text0, text1, text0, text1, text0, text1, text0, text1, text0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering thread 1\n",
      "Registering thread 2\n",
      "Registering thread 3\n",
      "Registering thread 4\n",
      "Registering thread 5\n",
      "Registering thread 6\n",
      "Registering thread 7\n",
      "Registering thread 8\n",
      "Registering thread 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(text)):\n",
    "    print(f\"Registering thread {i + 1}\")\n",
    "    result = Thread(target=text_to_audio, args=[text[i], audio_file_path])\n",
    "    threads.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "Created the mel spectrogram\n",
      "Synthesizing the waveform:\n",
      "{| ████████████████ 76000/76800 | Batch Size: 8 | Gen Rate: 0.9kHz | }\n",
      "Total time: 81.52424812316895\n",
      "{| ████████████████ 84600/86400 | Batch Size: 9 | Gen Rate: 1.0kHz | }\n",
      "Total time: 82.84767293930054\n",
      "{| ████████████████ 85500/86400 | Batch Size: 9 | Gen Rate: 1.0kHz | }\n",
      "Total time: 82.86099910736084\n",
      "{| ████████████████ 85500/86400 | Batch Size: 9 | Gen Rate: 1.0kHz | }\n",
      "Total time: 82.85699129104614\n",
      "\n",
      "Total time: 82.8376817703247\n",
      "\n",
      "Total time: 82.45955991744995\n",
      "\n",
      "Total time: 83.23778676986694\n",
      "\n",
      "Total time: 83.08801484107971\n",
      "\n",
      "Total time: 83.4930260181427\n"
     ]
    }
   ],
   "source": [
    "for thread in threads:\n",
    "    thread.start()\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_list = np.array(global_wav).reshape(len(global_wav))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = np.array([*global_list[0]])\n",
    "a1 = np.array([*global_list[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [*a0, *np.zeros(10000), *a1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137680"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.stop()\n",
    "sd.play(temp, synthesizer.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plz work..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
